{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dimensionality reduction\n",
    "========"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os.path\n",
    "import sys\n",
    "\n",
    "# from svecon.HierarchicalGridSearchCV import HierarchicalGridSearchCV\n",
    "from svecon.EmptyTransformer import EmptyTransformer\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import Imputer, StandardScaler, LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from metric_learn import LMNN, NCA, LFDA, Covariance, CMAES, FullMatrixTransformer, NeuralNetworkTransformer\n",
    "from metric_learn import ITML_Supervised, SDML_Supervised, LSML_Supervised, RCA_Supervised\n",
    "\n",
    "import plotly\n",
    "from plotly import tools\n",
    "plotly.tools.set_credentials_file(username='sveco', api_key='8701ghzf0i')\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "py.init_notebook_mode()\n",
    "\n",
    "datasetsDirectory = 'datasets'\n",
    "resultsDirectory = 'datasets-results-dim-reduction'\n",
    "\n",
    "if not os.path.exists(resultsDirectory):\n",
    "    os.makedirs(resultsDirectory)\n",
    "\n",
    "default_n_jobs = 8\n",
    "default_random_state = 789\n",
    "default_n_folds = 10\n",
    "default_shuffle = True\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.handlers = []\n",
    "fh = logging.FileHandler(\"{}/error.log\".format(resultsDirectory))\n",
    "fh.setLevel(logging.DEBUG)\n",
    "logger.addHandler(fh)\n",
    "fh = logging.StreamHandler(sys.stdout)\n",
    "fh.setLevel(logging.ERROR)\n",
    "logger.addHandler(fh)\n",
    "\n",
    "defaultScatterMarker=dict(\n",
    "    size=10,\n",
    "    colorscale='Viridis',\n",
    "    opacity=0.5\n",
    ")\n",
    "\n",
    "# np.set_printoptions(precision=7, suppress=True, threshold=np.nan)\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.10f}\".format(x)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob, os\n",
    "\n",
    "datasets = []\n",
    "for file in glob.glob(\"{}/*.csv\".format(datasetsDirectory)):\n",
    "    datasets.append(file)\n",
    "datasets.sort()\n",
    "\n",
    "# datasets.remove('datasets/soybean-large.csv')\n",
    "\n",
    "# datasets = datasets[7:8]\n",
    "logging.info(\"Datasets: \" + str(datasets))\n",
    "\n",
    "for x in datasets:\n",
    "    print(x, pd.read_csv(x, sep=',', skiprows=1, header=0).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def makeScatter(Xy):\n",
    "    X,y = Xy\n",
    "    X = X.T\n",
    "    if X.shape[0] in (0,1): return go.Scatter()\n",
    "    \n",
    "    return go.Scatter(x=X[0], y=X[1], #z=X_train_pca[2],\n",
    "        text=y, mode='markers', marker={**defaultScatterMarker, 'color':y}, \n",
    "    )\n",
    "\n",
    "import os.path\n",
    "def loadOrCalculateAndSave(datasetName, X, y, method, params):\n",
    "    fname = '{}/{}-{}-{}.csv'.format('precalculated-projections', datasetName, method.__name__, params)\n",
    "    if os.path.isfile(fname):\n",
    "        Xt = np.loadtxt(fname)\n",
    "    else:\n",
    "        try:\n",
    "            Xt = method(**params).fit_transform(X, y)\n",
    "        except:\n",
    "            Xt = np.ndarray(shape=(1,2))\n",
    "        np.savetxt(fname, Xt)\n",
    "    return Xt, y\n",
    "\n",
    "for filename in datasets:\n",
    "    results = []\n",
    "    datasetName = filename[len(datasetsDirectory)+1:-4]\n",
    "    \n",
    "    data = pd.read_csv(filename, sep=',', skiprows=1, header=0)\n",
    "    y = data['class']\n",
    "    X = data.drop(['class'], axis=1).values\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(y)\n",
    "    \n",
    "    imputer = Imputer(missing_values='NaN', strategy='mean', axis=0, verbose=0, copy=False)\n",
    "    X = imputer.fit_transform(X)\n",
    "    \n",
    "    trace1 = makeScatter(loadOrCalculateAndSave(datasetName, X, y, PCA, {'n_components':2}))\n",
    "    trace2 = makeScatter(loadOrCalculateAndSave(datasetName, X, y, TSNE, {'n_components':2}))\n",
    "    trace3 = makeScatter(loadOrCalculateAndSave(datasetName, X, y, LFDA, {'dim':2, 'k':2}))\n",
    "    trace4 = makeScatter(loadOrCalculateAndSave(datasetName, X, y, CMAES, {'transformer':NeuralNetworkTransformer(layers=(6, 2,)), 'n_neighbors':4, 'n_gen':100}))\n",
    "\n",
    "    fig = tools.make_subplots(\n",
    "        rows=1,\n",
    "        cols=4,\n",
    "        print_grid=False,\n",
    "        subplot_titles=('PCA', 'T-SNE', 'FDA', 'CMAES')\n",
    "    )\n",
    "\n",
    "    fig.append_trace(trace1, 1, 1)\n",
    "    fig.append_trace(trace2, 1, 2)\n",
    "    fig.append_trace(trace3, 1, 3)\n",
    "    fig.append_trace(trace4, 1, 4)\n",
    "\n",
    "    fig['layout'].update(title='{} dataset {}, {} classes'.format(datasetName, X.shape, len(np.unique(y))), showlegend=False)\n",
    "#     fig['layout'].update(height=600, width=1200, title='i <3 subplots')\n",
    "#     plot_url = py.plot(fig, filename='make-subplots')\n",
    "    py.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Authors: Fabian Pedregosa <fabian.pedregosa@inria.fr>\n",
    "#          Olivier Grisel <olivier.grisel@ensta.org>\n",
    "#          Mathieu Blondel <mathieu@mblondel.org>\n",
    "#          Gael Varoquaux\n",
    "# License: BSD 3 clause (C) INRIA 2011\n",
    "\n",
    "print(__doc__)\n",
    "from time import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import offsetbox\n",
    "from sklearn import (manifold, datasets, decomposition, ensemble,\n",
    "                     discriminant_analysis, random_projection)\n",
    "\n",
    "digits = datasets.load_digits(n_class=6)\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "n_samples, n_features = X.shape\n",
    "n_neighbors = 30\n",
    "\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "# Scale and visualize the embedding vectors\n",
    "def plot_embedding(X, title=None):\n",
    "    x_min, x_max = np.min(X, 0), np.max(X, 0)\n",
    "    X = (X - x_min) / (x_max - x_min)\n",
    "\n",
    "    plt.figure()\n",
    "    ax = plt.subplot(111)\n",
    "    for i in range(X.shape[0]):\n",
    "        plt.text(X[i, 0], X[i, 1], str(digits.target[i]),\n",
    "                 color=plt.cm.Set1(y[i] / 10.),\n",
    "                 fontdict={'weight': 'bold', 'size': 9})\n",
    "\n",
    "#     if hasattr(offsetbox, 'AnnotationBbox'):\n",
    "#         # only print thumbnails with matplotlib > 1.0\n",
    "#         shown_images = np.array([[1., 1.]])  # just something big\n",
    "#         for i in range(digits.data.shape[0]):\n",
    "#             dist = np.sum((X[i] - shown_images) ** 2, 1)\n",
    "#             if np.min(dist) < 4e-3:\n",
    "#                 # don't show points that are too close\n",
    "#                 continue\n",
    "#             shown_images = np.r_[shown_images, [X[i]]]\n",
    "#             imagebox = offsetbox.AnnotationBbox(\n",
    "#                 offsetbox.OffsetImage(digits.images[i], cmap=plt.cm.gray_r),\n",
    "#                 X[i])\n",
    "#             ax.add_artist(imagebox)\n",
    "    plt.xticks([]), plt.yticks([])\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "# Plot images of the digits\n",
    "n_img_per_row = 20\n",
    "img = np.zeros((10 * n_img_per_row, 10 * n_img_per_row))\n",
    "for i in range(n_img_per_row):\n",
    "    ix = 10 * i + 1\n",
    "    for j in range(n_img_per_row):\n",
    "        iy = 10 * j + 1\n",
    "        img[ix:ix + 8, iy:iy + 8] = X[i * n_img_per_row + j].reshape((8, 8))\n",
    "\n",
    "plt.imshow(img, cmap=plt.cm.binary)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.title('A selection from the 64-dimensional digits dataset')\n",
    "\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "# Random 2D projection using a random unitary matrix\n",
    "print(\"Computing random projection\")\n",
    "rp = random_projection.SparseRandomProjection(n_components=2, random_state=42)\n",
    "X_projected = rp.fit_transform(X)\n",
    "plot_embedding(X_projected, \"Random Projection of the digits\")\n",
    "\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "# Projection on to the first 2 principal components\n",
    "\n",
    "print(\"Computing PCA projection\")\n",
    "t0 = time()\n",
    "X_pca = decomposition.TruncatedSVD(n_components=2).fit_transform(X)\n",
    "plot_embedding(X_pca,\n",
    "               \"Principal Components projection of the digits (time %.2fs)\" %\n",
    "               (time() - t0))\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "# Projection on to the first 2 linear discriminant components\n",
    "\n",
    "print(\"Computing Linear Discriminant Analysis projection\")\n",
    "X2 = X.copy()\n",
    "X2.flat[::X.shape[1] + 1] += 0.01  # Make X invertible\n",
    "t0 = time()\n",
    "X_lda = discriminant_analysis.LinearDiscriminantAnalysis(n_components=2).fit_transform(X2, y)\n",
    "plot_embedding(X_lda,\n",
    "               \"Linear Discriminant projection of the digits (time %.2fs)\" %\n",
    "               (time() - t0))\n",
    "\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "# Isomap projection of the digits dataset\n",
    "print(\"Computing Isomap embedding\")\n",
    "t0 = time()\n",
    "X_iso = manifold.Isomap(n_neighbors, n_components=2).fit_transform(X)\n",
    "print(\"Done.\")\n",
    "plot_embedding(X_iso,\n",
    "               \"Isomap projection of the digits (time %.2fs)\" %\n",
    "               (time() - t0))\n",
    "\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "# Locally linear embedding of the digits dataset\n",
    "print(\"Computing LLE embedding\")\n",
    "clf = manifold.LocallyLinearEmbedding(n_neighbors, n_components=2,\n",
    "                                      method='standard')\n",
    "t0 = time()\n",
    "X_lle = clf.fit_transform(X)\n",
    "print(\"Done. Reconstruction error: %g\" % clf.reconstruction_error_)\n",
    "plot_embedding(X_lle,\n",
    "               \"Locally Linear Embedding of the digits (time %.2fs)\" %\n",
    "               (time() - t0))\n",
    "\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "# Modified Locally linear embedding of the digits dataset\n",
    "print(\"Computing modified LLE embedding\")\n",
    "clf = manifold.LocallyLinearEmbedding(n_neighbors, n_components=2,\n",
    "                                      method='modified')\n",
    "t0 = time()\n",
    "X_mlle = clf.fit_transform(X)\n",
    "print(\"Done. Reconstruction error: %g\" % clf.reconstruction_error_)\n",
    "plot_embedding(X_mlle,\n",
    "               \"Modified Locally Linear Embedding of the digits (time %.2fs)\" %\n",
    "               (time() - t0))\n",
    "\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "# HLLE embedding of the digits dataset\n",
    "print(\"Computing Hessian LLE embedding\")\n",
    "clf = manifold.LocallyLinearEmbedding(n_neighbors, n_components=2,\n",
    "                                      method='hessian')\n",
    "t0 = time()\n",
    "X_hlle = clf.fit_transform(X)\n",
    "print(\"Done. Reconstruction error: %g\" % clf.reconstruction_error_)\n",
    "plot_embedding(X_hlle,\n",
    "               \"Hessian Locally Linear Embedding of the digits (time %.2fs)\" %\n",
    "               (time() - t0))\n",
    "\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "# LTSA embedding of the digits dataset\n",
    "print(\"Computing LTSA embedding\")\n",
    "clf = manifold.LocallyLinearEmbedding(n_neighbors, n_components=2,\n",
    "                                      method='ltsa')\n",
    "t0 = time()\n",
    "X_ltsa = clf.fit_transform(X)\n",
    "print(\"Done. Reconstruction error: %g\" % clf.reconstruction_error_)\n",
    "plot_embedding(X_ltsa,\n",
    "               \"Local Tangent Space Alignment of the digits (time %.2fs)\" %\n",
    "               (time() - t0))\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "# MDS  embedding of the digits dataset\n",
    "print(\"Computing MDS embedding\")\n",
    "clf = manifold.MDS(n_components=2, n_init=1, max_iter=100)\n",
    "t0 = time()\n",
    "X_mds = clf.fit_transform(X)\n",
    "print(\"Done. Stress: %f\" % clf.stress_)\n",
    "plot_embedding(X_mds,\n",
    "               \"MDS embedding of the digits (time %.2fs)\" %\n",
    "               (time() - t0))\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# Random Trees embedding of the digits dataset\n",
    "print(\"Computing Totally Random Trees embedding\")\n",
    "hasher = ensemble.RandomTreesEmbedding(n_estimators=200, random_state=0,\n",
    "                                       max_depth=5)\n",
    "t0 = time()\n",
    "X_transformed = hasher.fit_transform(X)\n",
    "pca = decomposition.TruncatedSVD(n_components=2)\n",
    "X_reduced = pca.fit_transform(X_transformed)\n",
    "\n",
    "plot_embedding(X_reduced,\n",
    "               \"Random forest embedding of the digits (time %.2fs)\" %\n",
    "               (time() - t0))\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "# Spectral embedding of the digits dataset\n",
    "print(\"Computing Spectral embedding\")\n",
    "embedder = manifold.SpectralEmbedding(n_components=2, random_state=0,\n",
    "                                      eigen_solver=\"arpack\")\n",
    "t0 = time()\n",
    "X_se = embedder.fit_transform(X)\n",
    "\n",
    "plot_embedding(X_se,\n",
    "               \"Spectral embedding of the digits (time %.2fs)\" %\n",
    "               (time() - t0))\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "# t-SNE embedding of the digits dataset\n",
    "print(\"Computing t-SNE embedding\")\n",
    "tsne = manifold.TSNE(n_components=2, init='pca', random_state=0)\n",
    "t0 = time()\n",
    "X_tsne = tsne.fit_transform(X)\n",
    "plot_embedding(X_tsne, \"t-SNE embedding of the digits (time %.2fs)\" % (time() - t0))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------\n",
    "# CMAES embedding of the digits dataset\n",
    "print(\"Computing CMAES embedding\")\n",
    "cmaes = CMAES(dim=2, n_gen=100, n_neighbors=8, knn_weights='distance')\n",
    "t0 = time()\n",
    "X_cmaes = cmaes.fit_transform(X, y)\n",
    "plot_embedding(X_cmaes, \"CMAES embedding of the digits (time %.2fs)\" % (time() - t0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cmaes.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import offsetbox\n",
    "\n",
    "from sklearn.datasets import fetch_mldata, load_digits, fetch_olivetti_faces\n",
    "\n",
    "\n",
    "# dataset = load_digits(n_class=10)\n",
    "dataset = fetch_mldata('MNIST original')\n",
    "dataset = fetch_olivetti_faces()\n",
    "X = dataset.data\n",
    "y = dataset.target\n",
    "\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "# X = pd.DataFrame(X)\n",
    "# X['class'] = pd.Series(y, index=X.index)\n",
    "\n",
    "# print(X.shape)\n",
    "# # X.to_csv('datasets/mnist.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
