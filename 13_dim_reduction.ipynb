{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dimensionality reduction\n",
    "========"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os.path\n",
    "import sys\n",
    "\n",
    "# from svecon.HierarchicalGridSearchCV import HierarchicalGridSearchCV\n",
    "# from svecon.EmptyTransformer import EmptyTransformer\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import Imputer, StandardScaler, LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from metric_learn import LMNN, NCA, LFDA, Covariance, MetricEvolution, NeuralNetworkTransformer, FullMatrixTransformer\n",
    "from metric_learn import ITML_Supervised, SDML_Supervised, LSML_Supervised, RCA_Supervised\n",
    "ME = MetricEvolution\n",
    "\n",
    "import plotly\n",
    "from plotly import tools\n",
    "plotly.tools.set_credentials_file(username='sveco', api_key='8701ghzf0i')\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "py.init_notebook_mode()\n",
    "\n",
    "datasetsDirectory = 'datasets'\n",
    "resultsDirectory = 'datasets-results-dim-reduction'\n",
    "graphsDirectory = 'datasets-graphs-dim-reduction'\n",
    "\n",
    "if not os.path.exists(resultsDirectory):\n",
    "    os.makedirs(resultsDirectory)\n",
    "    \n",
    "if not os.path.exists(graphsDirectory):\n",
    "    os.makedirs(graphsDirectory)\n",
    "\n",
    "default_n_jobs = 8\n",
    "default_random_state = 789\n",
    "default_n_folds = 10\n",
    "default_shuffle = True\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.handlers = []\n",
    "fh = logging.FileHandler(\"{}/error.log\".format(resultsDirectory))\n",
    "fh.setLevel(logging.DEBUG)\n",
    "logger.addHandler(fh)\n",
    "fh = logging.StreamHandler(sys.stdout)\n",
    "fh.setLevel(logging.ERROR)\n",
    "logger.addHandler(fh)\n",
    "\n",
    "defaultScatterMarker=dict(\n",
    "    size=10,\n",
    "    colorscale='Viridis',\n",
    "    opacity=0.5\n",
    ")\n",
    "\n",
    "# np.set_printoptions(precision=7, suppress=True, threshold=np.nan)\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.5f}\".format(x)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob, os\n",
    "\n",
    "def rename(dir, pattern='*.csv'):\n",
    "    for pathAndFilename in glob.iglob(os.path.join(dir, pattern)):\n",
    "#         title, ext = os.path.splitext(os.path.basename(pathAndFilename))\n",
    "#         os.rename(pathAndFilename, os.path.join(dir, titlePattern % title + ext))\n",
    "        newFilename = pathAndFilename.replace('NeuralNetworkTransformer', 'NT')\n",
    "        os.rename(pathAndFilename, newFilename)\n",
    "\n",
    "rename(resultsDirectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob, os\n",
    "\n",
    "datasets = []\n",
    "for file in glob.glob(\"{}/*.csv\".format(datasetsDirectory)):\n",
    "    datasets.append(file)\n",
    "datasets.sort()\n",
    "\n",
    "# datasets.remove('datasets/soybean-large.csv')\n",
    "# datasets/balance-scale.csv (625, 5)\n",
    "# datasets/breast-cancer-wisconsin.csv (699, 10)\n",
    "# datasets.remove('datasets/digits10.csv') # (1797, 65)\n",
    "# datasets.remove('datasets/digits6.csv') # (1083, 65)\n",
    "# datasets/ionosphere.csv (351, 35)\n",
    "# datasets/iris.csv (150, 5)\n",
    "# datasets.remove('datasets/mice-protein.csv') # (1080, 78)\n",
    "# datasets/pima-indians-diabetes.csv (768, 9)\n",
    "# datasets/sonar.csv (208, 61)\n",
    "# datasets/soybean-large.csv (307, 36)\n",
    "# datasets/wine.csv (178, 14)\n",
    "\n",
    "# datasets = datasets[7:8]\n",
    "logging.info(\"Datasets: \" + str(datasets))\n",
    "\n",
    "for x in datasets:\n",
    "    print(x, pd.read_csv(x, sep=',', skiprows=1, header=0).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "import math\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "\n",
    "def makeScatter(X, y):\n",
    "    X = X.T\n",
    "    if X.shape[0] in (0,1): return go.Scatter()\n",
    "    \n",
    "    assert(X.shape[0]==2)\n",
    "    \n",
    "    return go.Scatter(x=X[0], y=X[1], #z=X_train_pca[2],\n",
    "        text=y, mode='markers', marker={**defaultScatterMarker, 'color':y}, \n",
    "    )\n",
    "\n",
    "def makeGraphBuilder(datasetName, X, y, perRow=4):\n",
    "    traces = []\n",
    "    models = []\n",
    "    scores = []\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "    def add(method, params):\n",
    "        model = method(**params)\n",
    "        model.set_params(**params)\n",
    "        models.append(model)\n",
    "\n",
    "        try:\n",
    "            if callable(getattr(model, 'transform', None)): # TSNE cant transform\n",
    "                Xt_train = model.fit_transform(X_train, y_train)\n",
    "                Xt_test = model.transform(X_test)\n",
    "            else:\n",
    "                Xt = model.fit_transform(np.concatenate((X_train, X_test)), np.concatenate((y_train, y_test)))\n",
    "                l = len(X_train)\n",
    "                Xt_train, Xt_test = Xt[:l], Xt[l:]\n",
    "\n",
    "#                 if isinstance(model, CMAES):\n",
    "#                     print(len(model.hof[0]), model.hof[0].fitness)\n",
    "\n",
    "            if Xt_test is not None:\n",
    "                knn = KNeighborsClassifier(n_neighbors=4, n_jobs=-1)\n",
    "                knn.fit(Xt_train, y_train)\n",
    "                scores.append(knn.score(Xt_test, y_test))\n",
    "\n",
    "                trace = makeScatter(\n",
    "                    np.concatenate((Xt_train, Xt_test), axis=0),\n",
    "                    np.concatenate((y_train, y_test), axis=0),\n",
    "                )\n",
    "            else:\n",
    "                scores.append(None)\n",
    "                trace = makeScatter(Xt_train, y_train)\n",
    "\n",
    "            traces.append(trace)\n",
    "        except ValueError:\n",
    "            scores.append(0)\n",
    "            traces.append(go.Scatter())\n",
    "            raise\n",
    "\n",
    "    def draw():\n",
    "        rows = math.ceil(len(traces)*1.0/perRow)\n",
    "\n",
    "        titles = []\n",
    "        for m,s in zip(models, scores):\n",
    "            if s is None:\n",
    "                titles.append('{}'.format(m.__class__.__name__))\n",
    "            else:\n",
    "                titles.append('{} {:.2f}%'.format(m.__class__.__name__, s*100))\n",
    "\n",
    "        fig = tools.make_subplots(\n",
    "            rows=rows,\n",
    "            cols=perRow,\n",
    "            print_grid=False,\n",
    "            subplot_titles=titles\n",
    "        )\n",
    "        for i,t in enumerate(traces):\n",
    "            if t is None: \n",
    "                fig.append_trace(py.plotly_empty(), 1+(i//perRow), 1+(i%perRow))\n",
    "            else:\n",
    "                fig.append_trace(t, 1+(i//perRow), 1+(i%perRow))\n",
    "\n",
    "        fig['layout'].update(title='{} dataset {}, {} classes'.format(datasetName, X.shape, len(np.unique(y))), showlegend=False)\n",
    "        fig['layout'].update(width=700)\n",
    "        fig['layout'].update(height=300*rows)\n",
    "        py.iplot(fig)\n",
    "        fig['layout'].update(titlefont={'size':28})\n",
    "        fig['layout'].update(width=2100)\n",
    "        fig['layout'].update(height=700*rows)\n",
    "        plotly.plotly.image.save_as(fig, filename='{}/{}-plot.png'.format(graphsDirectory, datasetName))\n",
    "\n",
    "    return add,draw\n",
    "\n",
    "def P(methods):\n",
    "    def c(**kwargs):\n",
    "        return Pipeline([(x.__name__.lower(),x()) for x in methods])\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for filename in datasets[0:]:\n",
    "    results = []\n",
    "    datasetName = filename[len(datasetsDirectory)+1:-4]\n",
    "    \n",
    "    data = pd.read_csv(filename, sep=',', skiprows=1, header=0)\n",
    "    y = data['class']\n",
    "    X = data.drop(['class'], axis=1).values\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(y)\n",
    "    \n",
    "    imputer = Imputer(missing_values='NaN', strategy='mean', axis=0, verbose=0, copy=False)\n",
    "    X = imputer.fit_transform(X)\n",
    "    \n",
    "    g,draw = makeGraphBuilder(datasetName, X, y, perRow=3)\n",
    "    \n",
    "    defaults = {\n",
    "        'transformer':'neuralnetwork',\n",
    "        't__layers':(2,),\n",
    "        \n",
    "        'n_gen': 3,\n",
    "        'class_separation': True,\n",
    "        'verbose': False,\n",
    "        'random_state': 41,\n",
    "    }\n",
    "\n",
    "    print(datasetName)\n",
    "    \n",
    "    start = time.clock()\n",
    "    \n",
    "    g(PCA, {'n_components':2})\n",
    "    g(TSNE, {'n_components':2}) # , 'perplexity':50\n",
    "    g(LFDA, {'dim':2, 'k':2})\n",
    "    \n",
    "#     end = time.clock()\n",
    "#     print(end - start)\n",
    "#     start = time.clock()\n",
    "    \n",
    "#     g(ME, {**defaults, 'classifier':'knn','c__n_neighbors':1,'c__n_jobs':-1,'c__weights':'uniform'})\n",
    "#     g(ME, {**defaults, 'classifier':'svc',})\n",
    "#     g(ME, {**defaults, 'classifier':'lsvc','c__dual':False,})\n",
    "#     g(ME, {**defaults, 'transformer':NeuralNetworkTransformer(layers=(2,2,), activation='tanh'), 'c__n_neighbors':1, })\n",
    "#     g(ME, {'transformer':NeuralNetworkTransformer(layers=(2,2,2,)), 'n_neighbors':1, 'n_gen':n_gen,'class_separation':0, 'verbose':verbose})\n",
    "    \n",
    "    end = time.clock()\n",
    "    print(end - start)\n",
    "    start = time.clock()\n",
    "    \n",
    "    good_transformer = 'full'\n",
    "    if X.shape[1]>15:\n",
    "        good_transformer = NeuralNetworkTransformer(layers=(10,8,6,4,))\n",
    "        good_transformer = 'diagonal'\n",
    "    \n",
    "#     g(P([ME, PCA]), {'pca__n_components':2, 'metricevolution__transformer': good_transformer})\n",
    "#     g(P([ME, TSNE]), {'tsne__n_components':2, 'tsne__perplexity': 30, 'metricevolution__transformer': good_transformer})\n",
    "#     if False and X.shape[1]>7:\n",
    "#         g(ME, {'transformer': NeuralNetworkTransformer(layers=(10,8,6,4,2))})\n",
    "#     else:\n",
    "#     g(P([ME, TSNE]), {'tsne__n_components':2, 'tsne__perplexity': 30, \n",
    "#                       'metricevolution__transformer': 'full', 'metricevolution__evolution_strategy':'dde', 'metricevolution__verbose':True, \n",
    "#                       'metricevolution__fitnesses':('class_separation',)})\n",
    "    \n",
    "    end = time.clock()\n",
    "    print(end - start)\n",
    "    start = time.clock()\n",
    "    \n",
    "#     g(P([ME, TSNE]), {'tsne__n_components':2, 'tsne__perplexity': 30, \n",
    "#                       'metricevolution__transformer': 'full', 'metricevolution__evolution_strategy':'de', 'metricevolution__verbose':True})\n",
    "\n",
    "    end = time.clock()\n",
    "    print(end - start)\n",
    "    start = time.clock()\n",
    "    \n",
    "#     g(P([ME, TSNE]), {'tsne__n_components':2, 'tsne__perplexity': 30, \n",
    "#                       'metricevolution__transformer': 'full', 'metricevolution__evolution_strategy':'cmaes', 'metricevolution__verbose':True})\n",
    "\n",
    "    end = time.clock()\n",
    "    print(end - start)\n",
    "    start = time.clock()\n",
    "    \n",
    "#     g(ME, {'transformer': 'full', 't__n_components': 2, 'evolution_strategy':'metricevolution'})\n",
    "#     g(ME, {'transformer': 'full', 't__n_components': 2, 'evolution_strategy':'metricevolution'})\n",
    "#     g(ME, {'transformer': 'kmeans', 't__transformer': 'full'})\n",
    "#     g(ME, {'transformer': 'kmeans', 't__transformer': 'diagonal', 't__n_clusters':2})\n",
    "#     g(ME, {'transformer': 'kmeans', 't__transformer': 'diagonal', 't__n_clusters':2, 't__function':'product'})\n",
    "#     g(P([ME, TSNE]), {'tsne__n_components':2, 'tsne__perplexity': 30, 'metricevolution__transformer': 'kmeans', 'metricevolution__t__transformer':'diagonal', 'metricevolution__t__n_classes': 'same'})\n",
    "#     g(P([ME, TSNE]), {'tsne__n_components':2, 'tsne__perplexity': 30, 'metricevolution__transformer': 'kmeans', 'metricevolution__t__transformer':'diagonal', 'metricevolution__t__n_classes': 'same', 'metricevolution__t__function':'product'})\n",
    "\n",
    "#     end = time.clock()\n",
    "#     print(end - start)\n",
    "#     start = time.clock()\n",
    "    \n",
    "#     g(ME, {'transformer':NeuralNetworkTransformer(layers=(2,)), 'n_neighbors':1, 'n_gen':n_gen,'classifier':'svm', 'verbose':verbose})\n",
    "#     g(ME, {'transformer':NeuralNetworkTransformer(layers=(2,2,)), 'n_neighbors':1, 'n_gen':n_gen,'classifier':'svm', 'verbose':verbose})\n",
    "#     g(ME, {'transformer':NeuralNetworkTransformer(layers=(2,2,2,)), 'n_neighbors':1, 'n_gen':n_gen,'classifier':'svm', 'verbose':verbose})\n",
    "\n",
    "#     end = time.clock()\n",
    "#     print(end - start)\n",
    "#     start = time.clock()\n",
    "    \n",
    "#     g(ME, {'transformer':NeuralNetworkTransformer(layers=(2,)), 'n_neighbors':1, 'n_gen':n_gen,'classifier':'lsvm', 'verbose':verbose})\n",
    "#     g(ME, {'transformer':NeuralNetworkTransformer(layers=(2,2,)), 'n_neighbors':1, 'n_gen':n_gen,'classifier':'lsvm', 'verbose':verbose})\n",
    "#     g(ME, {'transformer':NeuralNetworkTransformer(layers=(2,2,2,)), 'n_neighbors':1, 'n_gen':n_gen,'classifier':'lsvm', 'verbose':verbose})\n",
    "\n",
    "#     end = time.clock()\n",
    "#     print(end - start)\n",
    "#     g(ME, {'transformer':NeuralNetworkTransformer(layers=(2,2,), activation='tanh'), 'n_neighbors':1, 'n_gen':n_gen,'class_separation':0, 'verbose':verbose})\n",
    "#     g(ME, {'transformer':NeuralNetworkTransformer(layers=(2,2,2,), activation='tanh'), 'n_neighbors':1, 'n_gen':n_gen,'class_separation':0, 'verbose':verbose})\n",
    "#     g(ME, {'transformer':NeuralNetworkTransformer(layers=(4,3,2,2,), activation='tanh'), 'n_neighbors':1, 'n_gen':n_gen,'class_separation':0, 'verbose':verbose})\n",
    "\n",
    "#     g(ME, {'transformer':NeuralNetworkTransformer(layers=(2,2,), activation='none'), 'n_neighbors':1, 'n_gen':n_gen,'class_separation':0, 'verbose':verbose})\n",
    "#     g(ME, {'transformer':NeuralNetworkTransformer(layers=(2,2,2,), activation='none'), 'n_neighbors':1, 'n_gen':n_gen,'class_separation':0, 'verbose':verbose})\n",
    "#     g(ME, {'transformer':NeuralNetworkTransformer(layers=(4,3,2,2,), activation='none'), 'n_neighbors':1, 'n_gen':n_gen,'class_separation':0, 'verbose':verbose})\n",
    "\n",
    "#     g(ME, {'transformer':NeuralNetworkTransformer(layers=(2,)), 'n_neighbors':4, 'n_gen':n_gen,'class_separation':0, 'verbose':True})\n",
    "#     g(ME, {'transformer':NeuralNetworkTransformer(layers=(2,2,)), 'n_neighbors':4, 'n_gen':n_gen,'class_separation':0, 'verbose':True})\n",
    "#     g(ME, {'transformer':NeuralNetworkTransformer(layers=(2,2,2,), activation='relu'), 'n_neighbors':4, 'n_gen':n_gen,'class_separation':0, 'verbose':True})\n",
    "#     g(ME, {'transformer':NeuralNetworkTransformer(layers=(2,2,2,2,)), 'n_neighbors':4, 'n_gen':n_gen,'class_separation':0, 'verbose':True})\n",
    "    \n",
    "#     g(ME, {'transformer':NeuralNetworkTransformer(layers=(2,)), 'n_neighbors':8, 'n_gen':n_gen,'class_separation':1, 'verbose':True})\n",
    "#     g(ME, {'transformer':NeuralNetworkTransformer(layers=(4,3,2,)), 'n_neighbors':8, 'n_gen':n_gen,'class_separation':1, 'verbose':True})\n",
    "#     g(ME, {'transformer':NeuralNetworkTransformer(layers=(5,4,3,2,)), 'n_neighbors':8, 'n_gen':n_gen,'class_separation':1, 'verbose':True})\n",
    "#     g(ME, {'transformer':NeuralNetworkTransformer(layers=(16,8,4,2,)), 'n_neighbors':8, 'n_gen':n_gen,'class_separation':1, 'verbose':True})\n",
    "    \n",
    "#     g(ME, {'transformer':NeuralNetworkTransformer(layers=(2,)), 'n_neighbors':8, 'n_gen':n_gen,'class_separation':-1, 'verbose':True})\n",
    "#     g(ME, {'transformer':NeuralNetworkTransformer(layers=(4,3,2,)), 'n_neighbors':8, 'n_gen':n_gen,'class_separation':-1, 'verbose':True})\n",
    "#     g(ME, {'transformer':NeuralNetworkTransformer(layers=(5,4,3,2,)), 'n_neighbors':8, 'n_gen':n_gen,'class_separation':-1, 'verbose':True})\n",
    "#     g(ME, {'transformer':NeuralNetworkTransformer(layers=(16,8,4,2,)), 'n_neighbors':8, 'n_gen':n_gen,'class_separation':-1, 'verbose':True})\n",
    "\n",
    "    draw()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
