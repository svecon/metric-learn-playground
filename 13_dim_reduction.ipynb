{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dimensionality reduction\n",
    "========"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os.path\n",
    "import sys\n",
    "\n",
    "# from svecon.HierarchicalGridSearchCV import HierarchicalGridSearchCV\n",
    "from svecon.EmptyTransformer import EmptyTransformer\n",
    "\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import Imputer, StandardScaler, LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from metric_learn import LMNN, NCA, LFDA, Covariance, CMAES\n",
    "from metric_learn import ITML_Supervised, SDML_Supervised, LSML_Supervised, RCA_Supervised\n",
    "\n",
    "import plotly\n",
    "from plotly import tools\n",
    "plotly.tools.set_credentials_file(username='sveco', api_key='8701ghzf0i')\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "py.init_notebook_mode()\n",
    "\n",
    "datasetsDirectory = 'datasets'\n",
    "resultsDirectory = 'datasets-results-dim-reduction'\n",
    "\n",
    "if not os.path.exists(resultsDirectory):\n",
    "    os.makedirs(resultsDirectory)\n",
    "\n",
    "default_n_jobs = 8\n",
    "default_random_state = 789\n",
    "default_n_folds = 10\n",
    "default_shuffle = True\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.handlers = []\n",
    "fh = logging.FileHandler(\"{}/error.log\".format(resultsDirectory))\n",
    "fh.setLevel(logging.DEBUG)\n",
    "logger.addHandler(fh)\n",
    "fh = logging.StreamHandler(sys.stdout)\n",
    "fh.setLevel(logging.ERROR)\n",
    "logger.addHandler(fh)\n",
    "\n",
    "defaultScatterMarker=dict(\n",
    "    size=10,\n",
    "    colorscale='Viridis',\n",
    "    opacity=0.5\n",
    ")\n",
    "\n",
    "# np.set_printoptions(precision=7, suppress=True, threshold=np.nan)\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.10f}\".format(x)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob, os\n",
    "\n",
    "datasets = []\n",
    "for file in glob.glob(\"{}/*.csv\".format(datasetsDirectory)):\n",
    "    datasets.append(file)\n",
    "datasets.sort()\n",
    "\n",
    "# datasets.remove('datasets/soybean-large.csv')\n",
    "\n",
    "# datasets = datasets[-1:]\n",
    "logging.info(\"Datasets: \" + str(datasets))\n",
    "\n",
    "for x in datasets:\n",
    "    print(x, pd.read_csv(x, sep=',', skiprows=1, header=0).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def makeScatter(Xy):\n",
    "    X,y = Xy\n",
    "    X = X.T\n",
    "    return go.Scatter(x=X[0], y=X[1], #z=X_train_pca[2],\n",
    "        text=y, mode='markers', marker={**defaultScatterMarker, 'color':y}, \n",
    "    )\n",
    "\n",
    "import os.path\n",
    "def loadOrCalculateAndSave(datasetName, X, y, method):\n",
    "    fname = '{}/{}-{}-2D.csv'.format('precalculated-projections', datasetName, method.__class__.__name__)\n",
    "    if os.path.isfile(fname):\n",
    "        Xt = np.loadtxt(fname)\n",
    "    else:\n",
    "        try:\n",
    "            Xt = method.fit_transform(X, y)\n",
    "        except:\n",
    "            Xt = X\n",
    "        np.savetxt(fname, Xt)\n",
    "    return Xt, y\n",
    "\n",
    "for filename in datasets:\n",
    "    results = []\n",
    "    datasetName = filename[len(datasetsDirectory)+1:-4]\n",
    "    \n",
    "    data = pd.read_csv(filename, sep=',', skiprows=1, header=0)\n",
    "    y = data['class']\n",
    "    X = data.drop(['class'], axis=1).values\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(y)\n",
    "    \n",
    "    imputer = Imputer(missing_values='NaN', strategy='mean', axis=0, verbose=0, copy=False)\n",
    "    X = imputer.fit_transform(X)\n",
    "    \n",
    "    trace1 = makeScatter(loadOrCalculateAndSave(datasetName, X, y, PCA(n_components=2)))\n",
    "    trace2 = makeScatter(loadOrCalculateAndSave(datasetName, X, y, TSNE(n_components=2)))\n",
    "    trace3 = makeScatter(loadOrCalculateAndSave(datasetName, X, y, LFDA(dim=2, k=2)))\n",
    "    trace4 = makeScatter(loadOrCalculateAndSave(datasetName, X, y, CMAES(dim=2)))\n",
    "\n",
    "    fig = tools.make_subplots(\n",
    "        rows=1,\n",
    "        cols=4,\n",
    "        print_grid=False,\n",
    "        subplot_titles=('PCA', 'T-SNE', 'FDA', 'CMAES')\n",
    "    )\n",
    "\n",
    "    fig.append_trace(trace1, 1, 1)\n",
    "    fig.append_trace(trace2, 1, 2)\n",
    "    fig.append_trace(trace3, 1, 3)\n",
    "    fig.append_trace(trace4, 1, 4)\n",
    "\n",
    "    fig['layout'].update(title='{} dataset'.format(datasetName), showlegend=False)\n",
    "#     fig['layout'].update(height=600, width=1200, title='i <3 subplots')\n",
    "#     plot_url = py.plot(fig, filename='make-subplots')\n",
    "    py.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
