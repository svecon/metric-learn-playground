{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dimensionality reduction\n",
    "========"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob, os, os.path, sys, warnings, math, time, re\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import Imputer, StandardScaler, LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from metric_learn import LMNN, NCA, LFDA, Covariance, MetricEvolution, NeuralNetworkTransformer, FullMatrixTransformer\n",
    "from metric_learn import ITML_Supervised, SDML_Supervised, LSML_Supervised, RCA_Supervised\n",
    "ME = MetricEvolution\n",
    "\n",
    "%matplotlib inline\n",
    "from plotting.plots import *\n",
    "\n",
    "datasetsDirectory = 'datasets'\n",
    "resultsDirectory = 'results/dim-reduction'\n",
    "graphsDirectory = 'img/dim-reduction'\n",
    "\n",
    "if not os.path.exists(resultsDirectory):\n",
    "    os.makedirs(resultsDirectory)\n",
    "    \n",
    "if not os.path.exists(graphsDirectory):\n",
    "    os.makedirs(graphsDirectory)\n",
    "\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.5f}\".format(x)})\n",
    "\n",
    "import pickle\n",
    "def save_obj(obj, name):\n",
    "    with open('{}/{}.pkl'.format(resultsDirectory, name), 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name):\n",
    "    with open('{}/{}.pkl'.format(resultsDirectory, name), 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "    \n",
    "def exists_obj(name):\n",
    "    return os.path.exists('{}/{}.pkl'.format(resultsDirectory, name))\n",
    "\n",
    "def gfn(filename, folder='dimred'):\n",
    "    odir = '../thesis-distance-metric-learning/graphs/{}'.format(folder)\n",
    "    if not os.path.exists(odir):\n",
    "        os.makedirs(odir)\n",
    "    return '{}/{}'.format(odir, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob, os\n",
    "\n",
    "datasets = []\n",
    "for file in glob.glob(\"{}/*.csv\".format(datasetsDirectory)):\n",
    "    datasets.append(file)\n",
    "datasets.sort()\n",
    "\n",
    "for x in datasets:\n",
    "    print(x, pd.read_csv(x, sep=',', skiprows=1, header=0).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "skipDone = False\n",
    "def makeGraphBuilder(datasetName, X, y, perRow=4):\n",
    "    traces = []\n",
    "    models = []\n",
    "    scores = []\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "    \n",
    "    imputer = Imputer(missing_values='NaN', strategy='mean', axis=0, verbose=0, copy=False)\n",
    "    X_train = imputer.fit_transform(X_train)\n",
    "    X_test = imputer.transform(X_test)\n",
    "    \n",
    "    sscaler = StandardScaler()\n",
    "    X_train = sscaler.fit_transform(X_train)\n",
    "    X_test = sscaler.transform(X_test)\n",
    "    \n",
    "    def add(methodName, model, canTransform=True):\n",
    "        filename = '{}__{}'.format(datasetName, methodName)\n",
    "        if skipDone and exists_obj(filename):\n",
    "            print('skipping {}, already exists'.format(filename))\n",
    "            return\n",
    "        \n",
    "#         model = method(**params)\n",
    "#         model.set_params(**params)\n",
    "        models.append(model)\n",
    "\n",
    "        try:\n",
    "            if canTransform: # TSNE cant transform\n",
    "                Xt_train = model.fit_transform(X_train, y_train)\n",
    "                Xt_test = model.transform(X_test)\n",
    "            else:\n",
    "                Xt = model.fit_transform(np.concatenate((X_train, X_test)), np.concatenate((y_train, y_test)))\n",
    "                l = len(X_train)\n",
    "                Xt_train, Xt_test = Xt[:l], Xt[l:]\n",
    "\n",
    "            knn = KNeighborsClassifier(n_neighbors=4, n_jobs=-1)\n",
    "            knn.fit(Xt_train, y_train)\n",
    "\n",
    "            score = knn.score(Xt_test, y_test)\n",
    "            wrong = knn.predict(Xt_test) != y_test\n",
    "            \n",
    "            print('{} has {}%'.format(methodName, score*100))\n",
    "\n",
    "            if exists_obj(filename):\n",
    "                previousRun = load_obj(filename)\n",
    "                print('{} previously had {}%'.format(methodName, previousRun['score']*100))\n",
    "                if previousRun['score'] >= score: return\n",
    "            \n",
    "            print('SAVING')\n",
    "            \n",
    "            data = {\n",
    "                'score': score,\n",
    "                'X_train': Xt_train,\n",
    "                'y_train': y_train,\n",
    "                'X_test': Xt_test,\n",
    "                'y_test': y_test,\n",
    "                'wrong': wrong,\n",
    "            }\n",
    "            save_obj(data, filename)\n",
    "        except:\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "#             raise\n",
    "\n",
    "    return add\n",
    "\n",
    "def P(methods):\n",
    "    def c(**kwargs):\n",
    "        return Pipeline([(x.__name__.lower(),x()) for x in methods])\n",
    "    return c\n",
    "\n",
    "def P(methods):\n",
    "    def c(**kwargs):\n",
    "        return Pipeline([(type(x).__name__.lower(),x) for x in methods])\n",
    "    return c()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sortedDatasetsBySize = [\n",
    " 'datasets/balance-scale.csv',\n",
    " 'datasets/breast-cancer.csv',\n",
    " 'datasets/gaussians.csv',\n",
    " 'datasets/iris.csv',\n",
    " 'datasets/pima-indians.csv',\n",
    " 'datasets/wine.csv',\n",
    "\n",
    " 'datasets/sonar.csv',\n",
    " 'datasets/mice-protein.csv',\n",
    " 'datasets/digits10.csv',\n",
    " 'datasets/digits6.csv',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for filename in sortedDatasetsBySize:#['datasets/balance-scale.csv', 'datasets/gaussians.csv']:#\n",
    "    results = []\n",
    "    datasetName = filename[len(datasetsDirectory)+1:-4]\n",
    "    \n",
    "    data = pd.read_csv(filename, sep=',', skiprows=1, header=0)\n",
    "    y = data['class']\n",
    "    X = data.drop(['class'], axis=1).values\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(y)\n",
    "    \n",
    "    g = makeGraphBuilder(datasetName, X, y, perRow=3)\n",
    "    \n",
    "    defaults = {\n",
    "#         'transformer':'neuralnetwork',\n",
    "#         't__layers':(2,),\n",
    "        \n",
    "        'n_gen': 100,\n",
    "#         'class_separation': True,\n",
    "#         'verbose': False,\n",
    "#         'random_state': 41,\n",
    "    }\n",
    "\n",
    "    print(datasetName)\n",
    "    \n",
    "    start = time.clock()\n",
    "    \n",
    "#     g('pca', PCA(n_components=2))\n",
    "#     g('tsne', TSNE(n_components=2)) # , 'perplexity':50\n",
    "#     g('lfda', LFDA(num_dims=2, k=2))\n",
    "#     g('cmaes', ME(t__n_components=2))\n",
    "    \n",
    "#     g('normpca', P([PCA(n_components=2) ]))\n",
    "#     g('normlfda', P([LFDA(num_dims=2, k=2), StandardScaler() ]))\n",
    "# #     g('normnca', P([NCA(num_dims=2) ]))\n",
    "#     g('normtsne', P([TSNE(n_components=2) ]) ,canTransform=False)\n",
    "    g('normcmaes', P([ME(**defaults, t__n_components=2) ]))\n",
    "    g('normcmaestsne', P([ME(**defaults, ), TSNE(n_components=2) ]), canTransform=False)\n",
    "    \n",
    "#     g('nnnone', P([ME(**defaults, transformer=NeuralNetworkTransformer(layers=(16,8,4,2,), activation=None)) ]))\n",
    "    deepL = (16,8,4,2,)\n",
    "    g('nnrelu', P([ME(**defaults, transformer=NeuralNetworkTransformer(layers=deepL, activation='relu')) ]))\n",
    "    g('nnsigm', P([ME(**defaults, transformer=NeuralNetworkTransformer(layers=deepL, activation='sigm')) ]))\n",
    "    g('nntanh', P([ME(**defaults, transformer=NeuralNetworkTransformer(layers=deepL, activation='tanh')) ]))\n",
    "    \n",
    "    shallowL = (8,2,)\n",
    "    g('nnsigmshallow', P([ME(**defaults, transformer=NeuralNetworkTransformer(layers=shallowL, activation='sigm')), StandardScaler() ]))\n",
    "#     g('nnsigmdeep', P([ME(**defaults, transformer=NeuralNetworkTransformer(layers=(2,2,2,2,2,2,2,2,2,2,), activation='sigm')), StandardScaler() ]))\n",
    "    \n",
    "    g('nntanhshallow', P([ME(**defaults, transformer=NeuralNetworkTransformer(layers=shallowL, activation='tanh')), StandardScaler() ]))\n",
    "#     g('nntanhdeep', P([ME(**defaults, transformer=NeuralNetworkTransformer(layers=(2,2,2,2,2,2,2,2,2,2,), activation='tanh')), StandardScaler() ]))\n",
    "    \n",
    "    g('nnrelushallow', P([ME(**defaults, transformer=NeuralNetworkTransformer(layers=shallowL, activation='relu')), StandardScaler() ]))\n",
    "#     g('nnreludeep', P([ME(**defaults, transformer=NeuralNetworkTransformer(layers=(2,2,2,2,2,2,2,2,2,2,), activation='relu')), StandardScaler() ]))\n",
    "    \n",
    "#     g('nnnoneshallow', P([ME(**defaults, transformer=NeuralNetworkTransformer(layers=shallowL, activation=None)), StandardScaler() ]))\n",
    "#     g('nnnonedeep', P([ME(**defaults, transformer=NeuralNetworkTransformer(layers=(2,2,2,2,2,2,2,2,2,2,), activation=None)), StandardScaler() ]))\n",
    "    \n",
    "#     end = time.clock()\n",
    "#     print(end - start)\n",
    "#     start = time.clock()\n",
    "    \n",
    "#     g(ME, {**defaults, 'classifier':'knn','c__n_neighbors':1,'c__n_jobs':-1,'c__weights':'uniform'})\n",
    "#     g(ME, {**defaults, 'classifier':'svc',})\n",
    "#     g(ME, {**defaults, 'classifier':'lsvc','c__dual':False,})\n",
    "#     g(ME, {**defaults, 'transformer':NeuralNetworkTransformer(layers=(2,2,), activation='tanh'), 'c__n_neighbors':1, })\n",
    "#     g(ME, {'transformer':NeuralNetworkTransformer(layers=(2,2,2,)), 'n_neighbors':1, 'n_gen':n_gen,'class_separation':0, 'verbose':verbose})\n",
    "    \n",
    "#     end = time.clock()\n",
    "#     print(end - start)\n",
    "#     start = time.clock()\n",
    "    \n",
    "#     good_transformer = 'full'\n",
    "#     if X.shape[1]>15:\n",
    "#         good_transformer = NeuralNetworkTransformer(layers=(10,8,6,4,))\n",
    "#         good_transformer = 'diagonal'\n",
    "    \n",
    "#     g(P([ME, PCA]), {'pca__n_components':2, 'metricevolution__transformer': good_transformer})\n",
    "#     g(P([ME, TSNE]), {'tsne__n_components':2, 'tsne__perplexity': 30, 'metricevolution__transformer': good_transformer})\n",
    "#     if False and X.shape[1]>7:\n",
    "#         g(ME, {'transformer': NeuralNetworkTransformer(layers=(10,8,6,4,2))})\n",
    "#     else:\n",
    "#     g(P([ME, TSNE]), {'tsne__n_components':2, 'tsne__perplexity': 30, \n",
    "#                       'metricevolution__transformer': 'full', 'metricevolution__evolution_strategy':'dde', 'metricevolution__verbose':True, \n",
    "#                       'metricevolution__fitnesses':('class_separation',)})\n",
    "    \n",
    "#     end = time.clock()\n",
    "#     print(end - start)\n",
    "#     start = time.clock()\n",
    "    \n",
    "#     g(P([ME, TSNE]), {'tsne__n_components':2, 'tsne__perplexity': 30, \n",
    "#                       'metricevolution__transformer': 'full', 'metricevolution__evolution_strategy':'de', 'metricevolution__verbose':True})\n",
    "\n",
    "#     end = time.clock()\n",
    "#     print(end - start)\n",
    "#     start = time.clock()\n",
    "    \n",
    "#     g(P([ME, TSNE]), {'tsne__n_components':2, 'tsne__perplexity': 30, \n",
    "#                       'metricevolution__transformer': 'full', 'metricevolution__evolution_strategy':'cmaes', 'metricevolution__verbose':True})\n",
    "\n",
    "#     end = time.clock()\n",
    "#     print(end - start)\n",
    "#     start = time.clock()\n",
    "    \n",
    "#     g(ME, {'transformer': 'full', 't__n_components': 2, 'evolution_strategy':'metricevolution'})\n",
    "#     g(ME, {'transformer': 'full', 't__n_components': 2, 'evolution_strategy':'metricevolution'})\n",
    "#     g(ME, {'transformer': 'kmeans', 't__transformer': 'full'})\n",
    "#     g(ME, {'transformer': 'kmeans', 't__transformer': 'diagonal', 't__n_clusters':2})\n",
    "#     g(ME, {'transformer': 'kmeans', 't__transformer': 'diagonal', 't__n_clusters':2, 't__function':'product'})\n",
    "#     g(P([ME, TSNE]), {'tsne__n_components':2, 'tsne__perplexity': 30, 'metricevolution__transformer': 'kmeans', 'metricevolution__t__transformer':'diagonal', 'metricevolution__t__n_classes': 'same'})\n",
    "#     g(P([ME, TSNE]), {'tsne__n_components':2, 'tsne__perplexity': 30, 'metricevolution__transformer': 'kmeans', 'metricevolution__t__transformer':'diagonal', 'metricevolution__t__n_classes': 'same', 'metricevolution__t__function':'product'})\n",
    "\n",
    "#     end = time.clock()\n",
    "#     print(end - start)\n",
    "#     start = time.clock()\n",
    "    \n",
    "#     g(ME, {'transformer':NeuralNetworkTransformer(layers=(2,)), 'n_neighbors':1, 'n_gen':n_gen,'classifier':'svm', 'verbose':verbose})\n",
    "#     g(ME, {'transformer':NeuralNetworkTransformer(layers=(2,2,)), 'n_neighbors':1, 'n_gen':n_gen,'classifier':'svm', 'verbose':verbose})\n",
    "#     g(ME, {'transformer':NeuralNetworkTransformer(layers=(2,2,2,)), 'n_neighbors':1, 'n_gen':n_gen,'classifier':'svm', 'verbose':verbose})\n",
    "\n",
    "#     end = time.clock()\n",
    "#     print(end - start)\n",
    "#     start = time.clock()\n",
    "    \n",
    "#     g(ME, {'transformer':NeuralNetworkTransformer(layers=(2,)), 'n_neighbors':1, 'n_gen':n_gen,'classifier':'lsvm', 'verbose':verbose})\n",
    "#     g(ME, {'transformer':NeuralNetworkTransformer(layers=(2,2,)), 'n_neighbors':1, 'n_gen':n_gen,'classifier':'lsvm', 'verbose':verbose})\n",
    "#     g(ME, {'transformer':NeuralNetworkTransformer(layers=(2,2,2,)), 'n_neighbors':1, 'n_gen':n_gen,'classifier':'lsvm', 'verbose':verbose})\n",
    "\n",
    "#     end = time.clock()\n",
    "#     print(end - start)\n",
    "#     g(ME, {'transformer':NeuralNetworkTransformer(layers=(2,2,), activation='tanh'), 'n_neighbors':1, 'n_gen':n_gen,'class_separation':0, 'verbose':verbose})\n",
    "#     g(ME, {'transformer':NeuralNetworkTransformer(layers=(2,2,2,), activation='tanh'), 'n_neighbors':1, 'n_gen':n_gen,'class_separation':0, 'verbose':verbose})\n",
    "#     g(ME, {'transformer':NeuralNetworkTransformer(layers=(4,3,2,2,), activation='tanh'), 'n_neighbors':1, 'n_gen':n_gen,'class_separation':0, 'verbose':verbose})\n",
    "\n",
    "#     g(ME, {'transformer':NeuralNetworkTransformer(layers=(2,2,), activation='none'), 'n_neighbors':1, 'n_gen':n_gen,'class_separation':0, 'verbose':verbose})\n",
    "#     g(ME, {'transformer':NeuralNetworkTransformer(layers=(2,2,2,), activation='none'), 'n_neighbors':1, 'n_gen':n_gen,'class_separation':0, 'verbose':verbose})\n",
    "#     g(ME, {'transformer':NeuralNetworkTransformer(layers=(4,3,2,2,), activation='none'), 'n_neighbors':1, 'n_gen':n_gen,'class_separation':0, 'verbose':verbose})\n",
    "\n",
    "#     g(ME, {'transformer':NeuralNetworkTransformer(layers=(2,)), 'n_neighbors':4, 'n_gen':n_gen,'class_separation':0, 'verbose':True})\n",
    "#     g(ME, {'transformer':NeuralNetworkTransformer(layers=(2,2,)), 'n_neighbors':4, 'n_gen':n_gen,'class_separation':0, 'verbose':True})\n",
    "#     g(ME, {'transformer':NeuralNetworkTransformer(layers=(2,2,2,), activation='relu'), 'n_neighbors':4, 'n_gen':n_gen,'class_separation':0, 'verbose':True})\n",
    "#     g(ME, {'transformer':NeuralNetworkTransformer(layers=(2,2,2,2,)), 'n_neighbors':4, 'n_gen':n_gen,'class_separation':0, 'verbose':True})\n",
    "    \n",
    "#     g(ME, {'transformer':NeuralNetworkTransformer(layers=(2,)), 'n_neighbors':8, 'n_gen':n_gen,'class_separation':1, 'verbose':True})\n",
    "#     g(ME, {'transformer':NeuralNetworkTransformer(layers=(4,3,2,)), 'n_neighbors':8, 'n_gen':n_gen,'class_separation':1, 'verbose':True})\n",
    "#     g(ME, {'transformer':NeuralNetworkTransformer(layers=(5,4,3,2,)), 'n_neighbors':8, 'n_gen':n_gen,'class_separation':1, 'verbose':True})\n",
    "#     g(ME, {'transformer':NeuralNetworkTransformer(layers=(16,8,4,2,)), 'n_neighbors':8, 'n_gen':n_gen,'class_separation':1, 'verbose':True})\n",
    "    \n",
    "#     g(ME, {'transformer':NeuralNetworkTransformer(layers=(2,)), 'n_neighbors':8, 'n_gen':n_gen,'class_separation':-1, 'verbose':True})\n",
    "#     g(ME, {'transformer':NeuralNetworkTransformer(layers=(4,3,2,)), 'n_neighbors':8, 'n_gen':n_gen,'class_separation':-1, 'verbose':True})\n",
    "#     g(ME, {'transformer':NeuralNetworkTransformer(layers=(5,4,3,2,)), 'n_neighbors':8, 'n_gen':n_gen,'class_separation':-1, 'verbose':True})\n",
    "#     g(ME, {'transformer':NeuralNetworkTransformer(layers=(16,8,4,2,)), 'n_neighbors':8, 'n_gen':n_gen,'class_separation':-1, 'verbose':True})\n",
    "\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "for file in glob.glob(\"{}/*.pkl\".format(resultsDirectory)):\n",
    "    results.append(file)\n",
    "results.sort()\n",
    "\n",
    "resultsByDataset = {}\n",
    "\n",
    "for x in results:\n",
    "    _,_,filename = re.split('/|\\\\\\\\', x)\n",
    "    datasetName,methodName = filename[:-4].split('__')\n",
    "    \n",
    "    if datasetName not in resultsByDataset:\n",
    "        resultsByDataset[datasetName] = {}\n",
    "\n",
    "    resultsByDataset[datasetName][methodName] = load_obj(filename[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "methodTitles = [\n",
    "#     ('nnnoneshallow', 'None shallow'),\n",
    "#     ('nnnonedeep', 'None deep'),\n",
    "    \n",
    "    ('nnsigmshallow', 'Shallow NN.Sigm'),\n",
    "#     ('nnsigmdeep', 'Sigm deep'),\n",
    "\n",
    "    ('nntanhshallow', 'Shallow NN.Tanh'),\n",
    "#     ('nntanhdeep', 'Tanh deep'),\n",
    "\n",
    "    ('nnrelushallow', 'Shallow NN.ReLU'),\n",
    "#     ('nnreludeep', 'ReLU deep'),\n",
    "    \n",
    "#     ('nnnone', 'None'),\n",
    "    ('nnsigm', 'Deep NN.Sigmoid'),\n",
    "    ('nntanh', 'Deep NN.Tanh'),\n",
    "    ('nnrelu', 'Deep NN.ReLU'),\n",
    "]\n",
    "for datasetName, alldata in resultsByDataset.items():\n",
    "#     if datasetName not in ['wine']: continue\n",
    "    N = sum([1 if x in alldata else 0 for x,y in methodTitles])\n",
    "    \n",
    "    i = 0\n",
    "    cols = 3\n",
    "    fig, axes = startGraphing('`{}` dataset'.format(datasetName), cols, N, size=(8, 3*(N//cols)))\n",
    "    for method, title in methodTitles:\n",
    "        \n",
    "        if method not in alldata:\n",
    "            plotEmpty(axes[i], title, 'Memory Error', hideAxis=True)\n",
    "            i += 1\n",
    "            continue\n",
    "        \n",
    "        data = alldata[method]\n",
    "        plotScatter(axes[i],title,**data, scoreIsAproximation='t-SNE' in title)\n",
    "        i += 1\n",
    "    endGraphing(fig, filename=gfn('{}'.format(datasetName), folder='dimrednn'), move_title=.89)\n",
    "    plt.subplots_adjust(wspace=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "methodTitles = [\n",
    "    ('normpca', 's:PCA'),\n",
    "    ('normnca', 's:NCA'),\n",
    "    ('normlfda', 's:LFDA'),\n",
    "    ('normcmaes', 's:CMAES.kNN'),\n",
    "    ('normtsne', 's:t-SNE'),\n",
    "    ('normcmaestsne', 's:CMAES.kNN+t-SNE'),    \n",
    "]\n",
    "for datasetName, alldata in resultsByDataset.items():\n",
    "#     if datasetName not in ['wine']: continue\n",
    "    N = 6 #sum([1 if x in alldata else 0 for x,y in methodTitles])\n",
    "    \n",
    "    i = 0\n",
    "    cols = 3\n",
    "#     nSamples,nDim = pd.read_csv('datasets/{}.csv'.format(datasetName), sep=',', skiprows=1, header=0).shape\n",
    "#     fig, axes = startGraphing('`{}` dataset: {} dimensions, {} samples'.format(datasetName, nDim, nSamples), cols, N, size=(8, 3*(N//cols)))\n",
    "    fig, axes = startGraphing('`{}` dataset'.format(datasetName), cols, N, size=(8, 3*(N//cols)))\n",
    "    for method, title in methodTitles:\n",
    "        \n",
    "        if method not in alldata:\n",
    "            plotEmpty(axes[i], title, 'Memory Error', hideAxis=True)\n",
    "            i += 1\n",
    "            continue\n",
    "        \n",
    "        data = alldata[method]\n",
    "        plotScatter(axes[i],title,**data, scoreIsAproximation='t-SNE' in title)\n",
    "        i += 1\n",
    "    endGraphing(fig, filename=gfn('{}'.format(datasetName)), move_title=.89)\n",
    "    plt.subplots_adjust(wspace=0)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
